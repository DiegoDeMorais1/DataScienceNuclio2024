{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e780925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d998bf2",
   "metadata": {},
   "source": [
    "## Leitura e Processamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'assets/household_demand/'\n",
    "DEVICE_INFO_DIR = 'assets/devices_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "devices = os.listdir(DATA_DIR)\n",
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1681030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar a série de cada equipamento num dicionário\n",
    "import re\n",
    "\n",
    "devices_data = pd.read_csv(DEVICE_INFO_DIR)\n",
    "\n",
    "series_d = {}\n",
    "for device in devices:\n",
    "    print(device)\n",
    "    \n",
    "    df = pd.read_csv(f'{DATA_DIR}{device}', parse_dates=['timestamp'])\n",
    "\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    device_name = re.sub('.csv', '', device)\n",
    "    \n",
    "    df_power = df['power']\n",
    "    \n",
    "    # agregar por granularidade horária\n",
    "    df_p_hour = df_power.resample('H').sum()\n",
    "    \n",
    "    series_d[device_name] = df_p_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([*series_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_d['boiler_226']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ba89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_d['washing_machine_343']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db02550",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([len(series_d[x]) for x in series_d]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diferentes períodos e tamanhos\n",
    "### começar na 2a feira 00:00\n",
    "series_trunc = {}\n",
    "for k, device in series_d.items():\n",
    "    print(k)\n",
    "    first_monday0000 = np.where(device.index.weekday + device.index.hour + device.index.minute == 0)[0][0]\n",
    "\n",
    "    # primeiros 21 dias\n",
    "    series_from_mon = device[first_monday0000:].head(24 * 21)\n",
    "\n",
    "    if len(series_from_mon) == 24 * 21:\n",
    "        series_trunc[k] = series_from_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_trunc['washing_machine_343']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aab45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamanho de cada série\n",
    "pd.Series([len(series_trunc[x]) for x in series_trunc]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc26ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# normalização (x-min(x)) / (max(x) - min(x))\n",
    "for k in series_trunc:\n",
    "    series_norm = MinMaxScaler().fit_transform(series_trunc[k].values.reshape(-1, 1)).flatten()\n",
    "    #series_d[k] = pd.Series(series_norm, index=series_d[k].index)\n",
    "    series_trunc[k] = pd.Series(series_norm)\n",
    "\n",
    "series_trunc['boiler_226']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b415b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df = pd.DataFrame(series_trunc)\n",
    "series_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05971ff",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba892183",
   "metadata": {},
   "source": [
    "#### Com base em variáveis explicativas (feature-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dfdab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df_list = []\n",
    "#for i, k in enumerate(series_trunc):\n",
    "for k, x in series_trunc.items():  \n",
    "    x = x.reset_index()\n",
    "    x['id'] = k\n",
    "    series_df_list.append(x)\n",
    "\n",
    "series_df_l = pd.concat(series_df_list, axis=0)\n",
    "series_df_l.columns = ['time', 'value', 'id']\n",
    "series_df_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.feature_extraction import MinimalFCParameters, EfficientFCParameters\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "feats = extract_features(series_df_l,\n",
    "                         default_fc_parameters=MinimalFCParameters(),\n",
    "                         column_id='id',\n",
    "                         column_value='value',\n",
    "                         column_sort='time')\n",
    "\n",
    "feats = impute(feats)\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d57067",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_scl = MinMaxScaler().fit_transform(feats)\n",
    "feats_scl = pd.DataFrame(feats_scl, columns=feats.columns, index=feats.index)\n",
    "print(feats_scl.shape)\n",
    "feats_scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e05274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "kmeans_kwargs = {\n",
    "    'init': 'k-means++',\n",
    "    'n_init': 10,\n",
    "    'max_iter': 300,\n",
    "}\n",
    "\n",
    "N_CLUSTERS = range(1, 16)\n",
    "\n",
    "# sum of squared errors, silhoette\n",
    "sse, silhouette_coefficients = [], []\n",
    "for k in N_CLUSTERS:\n",
    "    print(k)\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(feats_scl)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    if k > 1:\n",
    "        silhouette_coefficients.append(silhouette_score(feats_scl, kmeans.labels_))\n",
    "\n",
    "pd.Series(sse, index=N_CLUSTERS).plot(figsize=(12,6), \n",
    "                                      title='Soma dos Erros Quadrados para cada k',\n",
    "                                      xlabel='Numero de grupos', ylabel='Soma dos Erros Q.',\n",
    "                                      xticks=N_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores = pd.Series(silhouette_coefficients, index=N_CLUSTERS[1:])\n",
    "sil_scores.plot(figsize=(12,6), \n",
    "                title='Valor da métrica da silhouette',\n",
    "                xlabel='Numero de grupos', ylabel='Silhouette',\n",
    "                xticks=N_CLUSTERS[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41728468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "device_names = [f'{x}.csv' for x in feats_scl.index] \n",
    "\n",
    "devices_data = devices_data.loc[devices_data['files_names'].isin(device_names)]\n",
    "category = devices_data['appliance_category']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(category)\n",
    "\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce11d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(category).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2974d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "model = KMeans(\n",
    "    n_clusters=4,\n",
    "    init=\"k-means++\",\n",
    "    n_init=50,\n",
    "    max_iter=500,\n",
    ")\n",
    "\n",
    "feats_pca = pca.fit_transform(feats_scl)\n",
    "model.fit(feats_pca)\n",
    "\n",
    "pca_df = pd.DataFrame(\n",
    "    feats_pca,\n",
    "    columns=['PC1', 'PC2'],\n",
    ")\n",
    "\n",
    "pca_df['Predicted'] = model.labels_\n",
    "pca_df['Actual'] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "scat = sns.scatterplot(\n",
    "    \"PC1\",\n",
    "    \"PC2\",\n",
    "    s=150,\n",
    "    data=pca_df,\n",
    "    hue=\"Predicted\",\n",
    "    style=\"Actual\",\n",
    "    palette=\"Set2\"\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as hc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "\n",
    "clusters = hc.linkage(feats_scl, \n",
    "            method='ward', \n",
    "            metric=\"euclidean\")\n",
    "hc.dendrogram(Z=clusters, labels=feats_scl.index, orientation='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cd070",
   "metadata": {},
   "source": [
    "#### Com dados brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "?TimeSeriesKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef860f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of squared errors, silhoette\n",
    "sse, silhouette_coefficients = [], []\n",
    "for k in N_CLUSTERS:\n",
    "    print(k)\n",
    "    kmeans = TimeSeriesKMeans(n_clusters=k, metric='dtw',max_iter=30)\n",
    "    kmeans.fit(series_df)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    if k > 1:\n",
    "        silhouette_coefficients.append(silhouette_score(series_df, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29313d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sse, index=N_CLUSTERS).plot(figsize=(12,6), \n",
    "                                      title='Soma dos Erros Quadrados para cada k',\n",
    "                                      xlabel='Numero de grupos', ylabel='Soma dos Erros Q.',\n",
    "                                      xticks=N_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_scores = pd.Series(silhouette_coefficients, index=N_CLUSTERS[1:])\n",
    "sil_scores.plot(figsize=(12,6), \n",
    "                title='Valor da métrica da silhouette',\n",
    "                xlabel='Numero de grupos', ylabel='Silhouette',\n",
    "                xticks=N_CLUSTERS[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = TimeSeriesKMeans(n_clusters=2, metric='dtw',max_iter=100)\n",
    "\n",
    "feats_pca = pca.fit_transform(feats_scl)\n",
    "kmeans.fit(feats_pca)\n",
    "\n",
    "pca_df = pd.DataFrame(\n",
    "    feats_pca,\n",
    "    columns=['PC1', 'PC2'],\n",
    ")\n",
    "\n",
    "pca_df['Predicted'] = kmeans.labels_\n",
    "pca_df['Actual'] = category\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "scat = sns.scatterplot(\n",
    "    \"PC1\",\n",
    "    \"PC2\",\n",
    "    s=150,\n",
    "    data=pca_df,\n",
    "    hue=\"Predicted\",\n",
    "    style=\"Actual\",\n",
    "    palette=\"Set2\"\n",
    ")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8446e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argwhere(feats_pca[:,0] > 1.3).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ddd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_scl.iloc[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716e6cc",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
